import os
import json
import subprocess
import logging
from pathlib import Path
import sys
from datetime import timedelta, datetime
import requests
from typing import Optional, TYPE_CHECKING, Any
import argparse

if TYPE_CHECKING:
    from natasha import MorphVocab

# –ó–∞–º–µ–Ω—è–µ–º pymorphy2 –Ω–∞ natasha –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Python 3.12
try:
    from natasha import MorphVocab
except ImportError:
    # Fallback: –ø—Ä–æ—Å—Ç–∞—è –∑–∞–º–µ–Ω–∞ –±–µ–∑ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    MorphVocab = None

# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ telegram_sender.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–º –∂–µ –∫–∞—Ç–∞–ª–æ–≥–µ
try:
    from telegram_sender import send_files
except ImportError:
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ sys.path, –µ—Å–ª–∏ –∑–∞–ø—É—Å–∫ –∏–¥–µ—Ç –∏–∑ –¥—Ä—É–≥–æ–≥–æ –º–µ—Å—Ç–∞
    sys.path.append(str(Path(__file__).parent))
    from telegram_sender import send_files

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
VIDEO_SOURCE_DIR = Path("TV_video")
VIDEO_PROCESSED_DIR = VIDEO_SOURCE_DIR / "processed"
KEYWORDS_FILE = Path("keywords.json")
TEMP_DIR = Path("temp_processing")
RECOGNIZED_TEXT_DIR = Path("recognized_text")

# --- Hugging Face API ---
# !!! –í–ê–® –¢–û–ö–ï–ù –î–û–°–¢–£–ü–ê HUGGING FACE !!!
# –ü–æ–ª—É—á–∏—Ç–µ –µ–≥–æ –∑–¥–µ—Å—å: https://huggingface.co/settings/tokens
HF_API_TOKEN = "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" 
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ
API_URL = "https://api-inference.huggingface.co/models/openai/whisper-large-v3"

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
VIDEO_PROCESSED_DIR.mkdir(exist_ok=True)
TEMP_DIR.mkdir(exist_ok=True)
RECOGNIZED_TEXT_DIR.mkdir(exist_ok=True)

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ---

def transcribe_audio_with_segments(audio_path: Path) -> list:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞,
    –∏—Å–ø–æ–ª—å–∑—É—è Hugging Face Inference API —Å –º–æ–¥–µ–ª—å—é Whisper.
    """
    logger.info(f"–ó–∞–ø—É—Å–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –¥–ª—è {audio_path.name} —á–µ—Ä–µ–∑ Hugging Face API...")

    if not HF_API_TOKEN or "hf_YOUR_TOKEN_HERE" in HF_API_TOKEN:
        logger.error("–¢–æ–∫–µ–Ω Hugging Face API –Ω–µ —É–∫–∞–∑–∞–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π HF_API_TOKEN.")
        return []

    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
    
    with open(audio_path, "rb") as f:
        data = f.read()

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–∞–π–º-–∫–æ–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ (—á–∞–Ω–∫–∞)
    params = {"return_timestamps": "chunk"}
    
    try:
        response = requests.post(API_URL, headers=headers, data=data, params=params, timeout=300)
        response.raise_for_status()  # –í—ã–∑–æ–≤–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –∫–æ–¥–æ–≤ 4xx/5xx
        
        result = response.json()
        logger.info("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —á–µ—Ä–µ–∑ API —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

        if 'chunks' not in result:
            logger.warning("–û—Ç–≤–µ—Ç API –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ('chunks').")
            return []

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ API –≤ –Ω–∞—à –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç
        # –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ Whisper: {'chunks': [{'timestamp': [start, end], 'text': '...'}, ...]}
        segments = [
            {'start': chunk['timestamp'][0], 'end': chunk['timestamp'][1], 'text': chunk['text']}
            for chunk in result.get('chunks', []) if chunk.get('timestamp')
        ]
        
        return segments

    except requests.exceptions.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Hugging Face API: {e}")
        if e.response is not None:
            logger.error(f"–¢–µ–ª–æ –æ—Ç–≤–µ—Ç–∞ API: {e.response.text}")
        return []


def get_normalized_keywords(morph: Any) -> set:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ keywords.json."""
    if not KEYWORDS_FILE.exists():
        logger.error(f"–§–∞–π–ª –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {KEYWORDS_FILE}")
        return set()
    
    with open(KEYWORDS_FILE, 'r', encoding='utf-8') as f:
        keywords = json.load(f)
    
    if morph is None:
        # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫–∞–∫ –µ—Å—Ç—å
        normalized_keywords = set(keywords)
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(normalized_keywords)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (–±–µ–∑ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞).")
        return normalized_keywords
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ —Å –ø–æ–º–æ—â—å—é natasha
    normalized_keywords = set()
    for kw in keywords:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É —Å–ª–æ–≤–∞
            normalized = morph.normalize(kw)
            if normalized:
                normalized_keywords.add(normalized)
            else:
                normalized_keywords.add(kw.lower())  # Fallback –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–≤–∞ '{kw}': {e}")
            normalized_keywords.add(kw.lower())  # Fallback –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ {len(normalized_keywords)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤.")
    return normalized_keywords


def find_segments_with_keywords(segments: list, keywords: set, morph: Any) -> list:
    """–ù–∞—Ö–æ–¥–∏—Ç —Å–µ–≥–º–µ–Ω—Ç—ã, —Ç–µ–∫—Å—Ç –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞."""
    found_segments = []
    for segment in segments:
        text = segment.get('text', '').lower()
        if not text:
            continue
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        found = False
        if morph is None:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            for keyword in keywords:
                if keyword.lower() in text:
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ '{keyword}' –≤ —Å–µ–≥–º–µ–Ω—Ç–µ: \"{text[:50]}...\"")
                    found_segments.append(segment)
                    found = True
                    break
        else:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –≤ —Ç–µ–∫—Å—Ç–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            words_in_text = text.split()
            for word in words_in_text:
                try:
                    normalized_word = morph.normalize(word)
                    if normalized_word and normalized_word in keywords:
                        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ '{normalized_word}' –≤ —Å–µ–≥–º–µ–Ω—Ç–µ: \"{text[:50]}...\"")
                        found_segments.append(segment)
                        found = True
                        break
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–≤–∞ '{word}': {e}")
                    # Fallback: –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ
                    if word in keywords:
                        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ '{word}' –≤ —Å–µ–≥–º–µ–Ω—Ç–µ: \"{text[:50]}...\"")
                        found_segments.append(segment)
                        found = True
                        break
        
        if found:
            continue
            
    return found_segments


def extract_audio(video_path: Path, temp_audio_path: Path) -> bool:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É –∏–∑ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é ffmpeg."""
    logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ {video_path.name}...")
    command = [
        'ffmpeg', '-y',
        '-i', str(video_path),
        '-q:a', '0',      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
        '-map', 'a',       # –í—ã–±–∏—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ
        str(temp_audio_path)
    ]
    try:
        result = subprocess.run(command, check=True, capture_output=True, text=True, encoding='utf-8', errors='replace')
        logger.info("–ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ.")
        return True
    except FileNotFoundError:
        logger.error("ffmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–Ω–æ–º PATH.")
        return False
    except subprocess.CalledProcessError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e.stderr}")
        return False


def cut_video_segment(original_video: Path, segment: dict, output_path: Path) -> bool:
    """–í—ã—Ä–µ–∑–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç –≤–∏–¥–µ–æ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ—Ç–∫–∞–º —Å –ø–æ–º–æ—â—å—é ffmpeg."""
    start_time = segment['start']
    end_time = segment['end']
    duration = end_time - start_time
    
    logger.info(f"–í—ã—Ä–µ–∑–∫–∞ —Å—é–∂–µ—Ç–∞ –∏–∑ {original_video.name} —Å {start_time:.2f} –ø–æ {end_time:.2f}...")
    command = [
        'ffmpeg', '-y',
        '-ss', str(start_time),   # –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
        '-i', str(original_video),
        '-t', str(duration),       # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        '-c', 'copy',              # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤ –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è (–±—ã—Å—Ç—Ä–æ)
        str(output_path)
    ]
    try:
        result = subprocess.run(command, check=True, capture_output=True, text=True, encoding='utf-8', errors='replace')
        logger.info(f"–°—é–∂–µ—Ç —É—Å–ø–µ—à–Ω–æ –≤—ã—Ä–µ–∑–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_path.name}")
        return True
    except FileNotFoundError:
        logger.error("ffmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return False
    except subprocess.CalledProcessError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—Ä–µ–∑–∫–µ –≤–∏–¥–µ–æ: {e.stderr}")
        return False


def save_results_as_txt(results: list, channel_name: str, video_file: str = None) -> str:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≤ txt-—Ñ–∞–π–ª –≤ –ø–∞–ø–∫–µ recognized_text.
    –û–¥–∏–Ω —Ñ–∞–π–ª –Ω–∞ –≤–∏–¥–µ–æ, —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç–æ–º.
    """
    if not results:
        logger.warning("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ txt")
        return ""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = f"{channel_name}_recognized_text_{timestamp}"
    if video_file:
        base_name = f"{channel_name}_{Path(video_file).stem}_recognized_text_{timestamp}"
    output_path = RECOGNIZED_TEXT_DIR / f"{base_name}.txt"
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            for i, res in enumerate(results, 1):
                start = res.get('start') or res.get('start_time')
                end = res.get('end') or res.get('end_time')
                text = res.get('text', '')
                f.write(f"–°—é–∂–µ—Ç {i}\n")
                if start is not None and end is not None:
                    f.write(f"–í—Ä–µ–º—è: {start:.2f} - {end:.2f} —Å–µ–∫\n")
                f.write(f"–¢–µ–∫—Å—Ç: {text}\n\n")
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ txt: {output_path}")
        return str(output_path)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ txt: {e}")
        return ""


def process_all_videos():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –≤–∏–¥–µ–æ."""
    logger.info("–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ—Å—é–∂–µ—Ç–æ–≤...")
    morph = MorphVocab()
    keywords = get_normalized_keywords(morph)
    
    if not keywords:
        logger.warning("–ù–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞. –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω.")
        return

    for channel_dir in VIDEO_SOURCE_DIR.iterdir():
        if not channel_dir.is_dir() or channel_dir.name == "processed":
            continue

        channel_name = channel_dir.name
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–Ω–∞–ª–∞: {channel_name}")

        for video_file in channel_dir.glob("*.mp4"):
            logger.info(f"--- –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {video_file.name} ---")
            
            # 1. –ò–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ
            temp_audio = TEMP_DIR / f"{video_file.stem}.mp3"
            if not extract_audio(video_file, temp_audio):
                continue

            # 2. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ
            segments = transcribe_audio_with_segments(temp_audio)
            
            # 3. –ù–∞–π—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç—ã —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            found_segments = find_segments_with_keywords(segments, keywords, morph)

            # 4. –í—ã—Ä–µ–∑–∞—Ç—å, –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏ –æ—á–∏—Å—Ç–∏—Ç—å
            if found_segments:
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(found_segments)} —Å—é–∂–µ—Ç–æ–≤ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –≤ {video_file.name}")
                for i, segment in enumerate(found_segments):
                    cut_video_path = TEMP_DIR / f"{video_file.stem}_—Å—é–∂–µ—Ç_{i+1}.mp4"
                    if cut_video_segment(video_file, segment, cut_video_path):
                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è Telegram
                        start_td = timedelta(seconds=int(segment['start']))
                        end_td = timedelta(seconds=int(segment['end']))
                        caption = (
                            f"üì∫ –¢–µ–ª–µ–∫–∞–Ω–∞–ª: {channel_name}\n"
                            f"üïí –í—Ä–µ–º—è —Å—é–∂–µ—Ç–∞: {start_td} - {end_td}\n\n"
                            f"üìú –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{segment['text']}"
                        )
                        
                        logger.info("–û—Ç–ø—Ä–∞–≤–∫–∞ —Å—é–∂–µ—Ç–∞ –≤ Telegram...")
                        if send_files([str(cut_video_path)], caption=caption):
                            logger.info("–°—é–∂–µ—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.")
                        else:
                            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—é–∂–µ—Ç.")
                        
                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –≤—ã—Ä–µ–∑–∞–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                        cut_video_path.unlink()
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                save_results_as_txt(found_segments, channel_name, video_file.name)
            else:
                logger.info(f"–í —Ñ–∞–π–ª–µ {video_file.name} —Å—é–∂–µ—Ç–æ–≤ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª
            temp_audio.unlink()
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ
            processed_channel_dir = VIDEO_PROCESSED_DIR / channel_name
            processed_channel_dir.mkdir(exist_ok=True)
            video_file.rename(processed_channel_dir / video_file.name)
            logger.info(f"--- –§–∞–π–ª {video_file.name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω. ---\n")

    logger.info("–í—Å–µ –≤–∏–¥–µ–æ—Å—é–∂–µ—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")


def process_single_video(video_path_str, channel_name):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞."""
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {video_path_str} –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel_name}")
    video_path = Path(video_path_str)
    if not video_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {video_path}")
        return
    try:
        morph = MorphVocab() if 'MorphVocab' in globals() and MorphVocab else None
        keywords = get_normalized_keywords(morph)
        temp_audio = TEMP_DIR / f"{video_path.stem}.mp3"
        if not extract_audio(video_path, temp_audio):
            return
        segments = transcribe_audio_with_segments(temp_audio)
        found_segments = find_segments_with_keywords(segments, keywords, morph)
        if found_segments:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(found_segments)} —Å—é–∂–µ—Ç–æ–≤ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –≤ {video_path.name}")
            for i, segment in enumerate(found_segments):
                cut_video_path = TEMP_DIR / f"{video_path.stem}_—Å—é–∂–µ—Ç_{i+1}.mp4"
                if cut_video_segment(video_path, segment, cut_video_path):
                    start_td = timedelta(seconds=int(segment['start']))
                    end_td = timedelta(seconds=int(segment['end']))
                    caption = (
                        f"üì∫ –¢–µ–ª–µ–∫–∞–Ω–∞–ª: {channel_name}\n"
                        f"üïí –í—Ä–µ–º—è —Å—é–∂–µ—Ç–∞: {start_td} - {end_td}\n\n"
                        f"üìú –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{segment['text']}"
                    )
                    logger.info("–û—Ç–ø—Ä–∞–≤–∫–∞ —Å—é–∂–µ—Ç–∞ –≤ Telegram...")
                    if send_files([str(cut_video_path)], caption=caption):
                        logger.info("–°—é–∂–µ—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.")
                    else:
                        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—é–∂–µ—Ç.")
                    cut_video_path.unlink()
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            save_results_as_txt(found_segments, channel_name, video_path.name)
        else:
            logger.info(f"–í —Ñ–∞–π–ª–µ {video_path.name} —Å—é–∂–µ—Ç–æ–≤ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        temp_audio.unlink()
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ
        processed_channel_dir = VIDEO_PROCESSED_DIR / channel_name
        processed_channel_dir.mkdir(exist_ok=True)
        video_path.rename(processed_channel_dir / video_path.name)
        logger.info(f"--- –§–∞–π–ª {video_path.name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω. ---\n")
    except Exception as e:
        logger.critical(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {e}", exc_info=True)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Video processor for TV news segments.")
    parser.add_argument('--single', nargs=2, metavar=('VIDEO_PATH', 'CHANNEL_NAME'), help='–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∏–¥–µ–æ—Ñ–∞–π–ª –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞')
    parser.add_argument('--check-keywords-only', action='store_true', help='–¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å')
    args = parser.parse_args()

    if args.single:
        video_path_str, channel_name = args.single
        if args.check_keywords_only:
            # –¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
            video_path = Path(video_path_str)
            if not video_path.exists():
                sys.exit(1)
            try:
                morph = MorphVocab() if 'MorphVocab' in globals() and MorphVocab else None
                keywords = get_normalized_keywords(morph)
                temp_audio = TEMP_DIR / f"{video_path.stem}.mp3"
                if not extract_audio(video_path, temp_audio):
                    sys.exit(1)
                segments = transcribe_audio_with_segments(temp_audio)
                found_segments = find_segments_with_keywords(segments, keywords, morph)
                temp_audio.unlink(missing_ok=True)
                if found_segments:
                    print("FOUND_KEYWORDS")
                    sys.exit(0)
                else:
                    sys.exit(2)
            except Exception as e:
                logger.critical(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}", exc_info=True)
                sys.exit(1)
        else:
            process_single_video(video_path_str, channel_name)
    else:
        try:
            process_all_videos()
        except Exception as e:
            logger.critical(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {e}", exc_info=True) 